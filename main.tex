\documentclass[a4paper, 12pt]{extarticle}

\input{preamble.tex} 


% Based on 'Fun Template 1', available at https://www.overleaf.com/latex/templates/fun-template-1/drwvdzsrpgzz


\begin{document}

%================= Settings front page =================
\titre{Synthèse IA} %Titre du fichier .pdf
\UE{INFO-F311} %Nom de la UE
\sujet{Intelligence Artificielle} %Nom du sujet

\enseignant{T. \textsc{Lenaerts}}  %Nom des enseignants
% Use \\ TO BREAK LINE

\eleves{Rayan \textsc{Contuliano Bravo}}
% \maketitle
\makemargins %Afficher les marges
\makefrontpage
\maketoc

%=======================================================

% this is the orginal latex code of the template
% \input{example}

%================= Content =============================
\section{Introduction} % (fold)
\label{sec:introduction}

\begin{definition}{Qu'est-ce que l'ia}{iadef}
    L'intelligence artificielle est une branche de l'informatique qui crée des systèmes 
    qui pensent de manière \textbf{rationnelle}
\end{definition}

\begin{definition}{Décisions rationnelles}{decisionsrationnelles}
    Penser de manière rationnelle signifie qu'on va se concentrer sur le \textbf{choix de décisions}
    qui \textit{maximisent la probabilité} d'atteindre un objectif donné. On va faire agir les systèmes de 
    manière \textbf{optimale}
\end{definition}
\begin{remarks}\leavevmode
\begin{enumerate}
    \item     Être rationel signifie donc \textbf{maximiser} l'utilité attendue.
    \item On définis un objectif par son \textbf{utilité}.
\end{enumerate}
\end{remarks}

\begin{definition}{Agent}{agent}
    Un agent est un système qui perçoit son environnement par des \textbf{capteurs} et agit sur celui-ci par des \textbf{effecteurs}.
\end{definition}

\begin{definition}{Agent rationnel}{agentrationnel}
    Un agent rationnel est un agent qui agit de manière à maximiser son utilité attendue. 
\end{definition}

\begin{remark}\leavevmode
    Les \textbf{capteurs}, \textbf{effecteurs} et l'\textbf{environnement} permettent à l'agent 
    de percevoir et d'agir sur le monde de manière \textbf{rationnelle}. L'\textbf{agent} est le système qui prend les décisions.
\end{remark}

\begin{definition}{Fonction agent}{funca}
    La fonction agent est une fonction qui prend en entrée une séquence de perceptions et retourne une action.
    \begin{math}
        f: \PP^* \rightarrow \SA \SP
    \end{math}
\end{definition}

\begin{example}\leavevmode
    % inserer une image
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{./pictures/agent_func.png}
        \caption{Représentation fonction agent dans le jeu Tetris}
        \label{fig:agent} 
    \end{figure}
\end{example}

\begin{definition}{Programe Agent}{progagent}
    Un \textbf{programe agent} $l$ est \underline{exécuté} sur une \textbf{machine} $M$ 
    afin d'\underline{implémenter} la fonction agent $f$.
\end{definition}
\begin{remark}\leavevmode
    Les machines dans le monde réel sont \textbf{imparfaites} et \textbf{limitées} en temps et en mémoire.
\end{remark}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.25\textwidth]{./pictures/vac_state.png}
    \end{center}
    \caption{Etat de l'environnement de l'aspirateur}\label{fig:vac_state}
\end{figure}

% WARNING: Pas sur que ce soit utile/bonne façon de faire
\begin{example}\leavevmode
    Nous pouvons représenter un aspirateur comme un agent qui perçoit son environnement par des capteurs et agit sur celui-ci par des effecteurs.
    \begin{itemize}
        \item \textbf{Perception}: capteurs qui détectent la saleté et sa localisation dans l'espace
        \item \textbf{Action}: effecteurs qui déplacent l'aspirateur dans l'espace et aspire ou non
    \end{itemize}
    En imaginant la situation en figure \ref{fig:vac_state}, nous pouvons définir la fonction agent de l'aspirateur comme suit:
    \begin{table}[H]
        \caption{Fonction agent de l'aspirateur}\label{tab:agent_func}
        \begin{center}
            \begin{tabular}[c]{|l|l|}
                \hline
                \multicolumn{1}{|c|}{\textbf{Sequence de perception}} & 
                \multicolumn{1}{c|}{\textbf{Action}} \\
                \hline

                [A, Clean] & Right \\
                \hline
                [A, Dirty] & Suck \\
                \hline
                [B, Clean] & Left\\
                \hline
                [B, Dirty] & Suck\\
                \hline
                [A, Clean], [B, Clean] & Left\\
                \hline
                [A, Clean], [B, Dirty] & Suck\\
                \hline
                etc... & etc...\\
                \hline
            \end{tabular}
        \end{center}
    \end{table}
\end{example}

Pour que notre agent soit bien rationnel, il nous faut une manière de \textbf{mesurer} la \textbf{performance}
de celui-ci. Pour cela, nous allons définir une \textbf{fonction de performance} qui va mesurer la qualité des actions de l'agent.

\begin{example}\leavevmode
    On peut lui faire gagner des points ou bien lui en retirer en fonction d'une action
\end{example}
De cette manière, l'agent va savoir quelles actions lui permettent de \textbf{maximiser} son utilité attendue.

Afin de bien déterminer un environnement, les particularité de notre agents, il nous faut 
\textbf{avant toute chose} définir \textbf{\textcolor{red}{PEAS}}

\begin{definition}{PEAS}{peas}
    \begin{itemize}
        \item \textbf{Performance}: mesure de la qualité des actions de l'agent
        \item \textbf{Environnement}: type d'environnement dans lequel l'agent va évoluer
        \item \textbf{Actuateurs}: les effecteurs de l'agent
        \item \textbf{Sensors}: les capteurs de l'agent
    \end{itemize} 
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.25\textwidth]{./pictures/pacman.png}
    \end{center}
    \caption{Environnement Pacman}\label{fig:pacman}
\end{figure}

\begin{example}\leavevmode
    Pour l'environnement Pacman de la figure \ref{fig:pacman}, nous pouvons définir PEAS comme suit:
    \begin{itemize}
        \item \textbf{Performance}: -1/pas, +10/nourriture, +500/partie gagnées, -500/mort, +200/tuer un fantôme effrayé
        \item \textbf{Environnement}: labyrinthe \textbf{dynamique }de pacman
        \item \textbf{Actuateurs}: Haut, Bas, Gauche, Droite
        \item \textbf{Capteurs}: L'état entier visible
    \end{itemize}



\end{example}

\begin{definition}{Types d'environnement}{envtype}
    Il y a plusieur type d'environnement:

    \begin{itemize}
        \item \textbf{Mono-agent}: un seul agent
        \item \textbf{Multi-agent}: plusieurs agents qui maximisent leur \textbf{propre} tâche (coop ou concurentiel)
        \item \textbf{Déterministe}: l'état de l'env est déterminé \textbf{seulement} par les actions de l'agent
        \item \textbf{Stochastique}: l'environnement est non déterministe
        \item \textbf{Épisodique}: les actions de l'agent n'affectent pas les actions futures
        \item \textbf{Séquentiel}: les actions de l'agent affectent les actions futures
        \item \textbf{Dynamique}: l'environnement peut changer pendant que l'agent réfléchit
        \item \textbf{Statique}: l'environnement ne change pas pendant que l'agent réfléchit
        \item \textbf{Complètement observable}: les capteurs de l'agent perçoivent l'état complet de l'environnement
        \item \textbf{Partiellement observable}: les capteurs de l'agent perçoivent une partie de l'état de l'environnement
        \item \textbf{Discret}: un nombre fini d'états
        \item \textbf{Continu}: un nombre infini d'états
        \item \textbf{Connu}: l'agent connait les lois de l'environnement
    \end{itemize}
\end{definition}

Il existe plusieurs types d'agents qui répondent à des environnements plus complexes:
\begin{itemize}
    \item \textbf{Agent réflexe simple}: l'agent choisit son action en fonction de la \textbf{dernière} perception
    \item \textbf{Agent réflexe basé sur un modèle}: l'agent choisit son action en fonction de la \textbf{dernière} perception et d'un \textbf{état interne}(dépend de l'\textbf{historique} des perceptions) 
    % \item \textbf{Agent réflexe avec état}: l'agent choisit son action en fonction de la \textbf{dernière} perception et de l'\textbf{historique} des perceptions
    \item \textbf{Agent fondés sur des buts}: l'agent choisit son action en fonction de la dernière perception 
        ainsi que des infos relatives à l'objectif
    \item \textbf{Agent fondés sur l'utilité}: l'agent choisit son action en fonction de 
        sa satisfaction par rapport à l'état résultant
\end{itemize}
% section Introduction (end)

\section{Recherche Non-Informée} % (fold)
\label{sec:recherche}

\begin{definition}{Recherche non-informée}{uninformed-search}
    La recherche \textbf{non-informée} est une stratégie de recherche qui n'utilise \textbf{pas}
    d'information sur l'état de l'environnement afin de le \textbf{guider} pour trouver une solution.
    Elle explore simplement l'espace de recherche de manière systèmatique. En utilisant souvent 
    des \textit{algorithmes} comme \textbf{DFS}, \textbf{BFS}.
\end{definition}

\begin{remark}\leavevmode
    La recherche non-informée est utilisée quand on ne connait pas l'état de l'environnement. 
    Lorsqu'on ne peut quantifier la qualité d'un état en utilisant des \textbf{information heuristiques}
\end{remark}

\begin{definition}{Agent de Plannification}{planningagent}
    Les agents de plannification font des \textbf{hypothèses} sur les conséquences des actions entreprises
    et utilisent un \textbf{modèle} de l'environnement pour trouver un plan qui atteint son objectif.
\end{definition}

\underline{\textbf{Résolution de problèmes par la recherches}}:
\begin{enumerate}
    \item \textbf{Formulation de l'objectif}: L'agent doit avoir un objectif afin 
        de pouvoir organiser son comportement. Ca permet de limiter l'espace de recherche (\textit{actions entreprises})
    \item \textbf{Formulation du problème}: L'agent doit avoir un moyen de représenter les actions et les états 
        afin de pouvoir les manipuler
    \item \textbf{Recherche de la solution}: Avant d'agir dans le monde réel, l'agent  fait  une 
        simulation de séquences d'actions dans son modèle de l'environnement jusqu'à trouver un séquence 
        qui mène à l'objectif. C'est  la \textit{solution}
    \item \textbf{Exécution de la solution}: L'agent exécute la séquence d'actions dans le monde réel
\end{enumerate}

\begin{note}
    Un plan est une séquence d'actions qui mène à l'objectif.
\end{note}

\subsection{Problème de recherches} % (fold)
\label{sub:probleme_de_recherches}

\begin{definition}{Problème de Recherche}{searchprob}
    Un problème de recherche est défini par:
    \begin{itemize}
        \item \textbf{Ensemble d'État $S$}: Une situation dans lequel l'environnement peut être agencé
        \item \textbf{État initial $s_o$}: l'état dans lequel le problème commence
        % \item \textbf{Actions}: les actions possibles
        % \item \textbf{Transition}: la fonction qui définit les conséquences des actions
        \item \textbf{Actions $A(s)$}: les actions possibles dans l'état $s$
        \item \textbf{Modèle de Transition $Result(s, a)$}: la fonction qui définit les conséquences des actions
        \item \textbf{Solution}: Une séquence d'actions qui mène de l'état initial à l'état final
        \item \textbf{État final}: l'état que l'on veut atteindre
    \end{itemize}
\end{definition}

% Fais un graph pour illustrer la roumanie

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.70\textwidth]{./pictures/roumanie.png}
    \end{center}
    \caption{Représentation simple de la Roumanie en graphe}\label{fig:romania}
\end{figure}



\begin{example}\leavevmode
    Voyage en Roumanie:
    \begin{itemize}
        \item \textbf{États}: les villes de Roumanie
        \item \textbf{État initial}: Arad
        \item \textbf{Actions}: les routes entre les villes adjacentes
        \item \textbf{Modèle de transition}: Atteindre une ville adjacente
        \item \textbf{Cout de l'action}: distance entre les villes
        \item \textbf{État final}: Bucharest 
    \end{itemize}
\end{example}

% subsection Probleme de recherches (end)

\subsection{Graphe d'espace d'état} % (fold)
\label{sub:graphe_d_espace_d_etat}

\begin{definition}{Graphe d'espace d'état}{stategraph}
    Un graphe d'espace d'état est un graphe qui représente les états et les actions possibles.
    \begin{itemize}
        \item \textbf{Noeuds}: les états
        \item \textbf{Arêtes}: les actions
    \end{itemize} 
    L'état initial est le noeud racine et l'état final est un noeud (ou plusieurs ?).
\end{definition}

\begin{warning}
    Dans ce genre de graphe, chaque état n'est représenté qu'\textbf{une seule fois}.
\end{warning}

\begin{remark}\leavevmode
    Il est fortement possible de ne pas pouvoir représenter un problème de recherche par un graphe d'espace d'état car 
    il y a \textbf{trop d'états} ou que les états sont \textbf{continus}.
\end{remark}

% subsection Graphe d'espace d'etat (end)

\subsection{Arbres de Recherches} % (fold)
\label{sub:arbres_de_recherches}

\begin{definition}{Arbre de Recherche}{searchtree}
    Un arbre de recherche est un arbre qui représente les états et les actions possibles.
    \begin{itemize}
        \item \textbf{Noeuds}: les états, plans pour arriver à ces états
        \item \textbf{Arêtes}: les actions
        \item \textbf{Enfants}: les états suivants (\textit{succeseurs})
    \end{itemize} 
    L'état initial est le noeud racine et l'état final est un noeud (ou plusieurs ?). 
    Les noeuds peuvent être représentés plusieurs fois, (\textbf{il est donc plus grand qu'un graphe d'espace d'état.})
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{./pictures/romst.png}
    \end{center}
    \caption{Arbre de recherche de la figure \ref{fig:romania}}\label{fig:romst}
\end{figure}

\subsubsection{Recherche dans un arbre de recherche} % (fold)
\label{sec:recherche_dans_un_arbre_de_recherche}

\begin{algorithm}[H]
    \floatname{algorithm}{Recherche dans un Arbre}
    \caption{Algorithme de recherche}\label{alg:stsearch}
    \begin{algorithmic}
        \Function{Tree-Search}{problème, stratégie} 
        \State initialise un noeud avec l'état initial du problème

        \Loop{
            \If{il ne peut plus y avoir d'état à explorer}
                \State \Return Erreur
            \EndIf
            \State choisis un noeud non exploré selon la stratégie
            \If{le noeud est l'état final}
                \State \Return le plan qui mène à l'état final
            \Else
                \State Développe le noeud et ajoute ses enfants à l'arbre
            \EndIf
        }
        \EndLoop
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{remarks}\leavevmode
\begin{enumerate}
    \item La frontière est l'ensemble des noeuds construits non explorés de l'arbre
    \item Pour développer un noeud de la frontiere, on le retire de la frontière et on l'ajoute à l'ensemble des noeuds explorés
        ses enfants sont ajoutés à la frontière
    \item La recherche dans un graphes est similaire à la recherche dans un arbre sauf qu'on doit vérifier si un noeud a déjà été visité
        avant de l'ajouter à la frontière
\end{enumerate}
\end{remarks}

% subsubsection Recherche dans un arbre de recherche (end)

% subsection Arbres de Recherches (end)

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.95\textwidth]{./pictures/bfsschema.jpg}
    \end{center}
    \caption{Sens d'éxécution BFS et DFS}\label{fig:bfsschema}
\end{figure}



\subsection{DFS} % (fold)
\label{sub:dfs}

\begin{definition}{DFS}{dfs}
    La recherche en profondeur (\textbf{DFS}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une pile (LIFO)
        \item \textbf{Stratégie}: on choisit le noeud le plus profond de la frontière
    \end{itemize} 
\end{definition}
% subsection DFS (end)

\subsection{BFS} % (fold) 
\label{sub:bfs} 

\begin{definition}{BFS}{bfs}
    La recherche en largeur (\textbf{BFS}) est une stratégie de recherche qui explore l'arbre en allant le plus large possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une file (FIFO)
        \item \textbf{Stratégie}: on choisit le noeud le moins profond de la frontière
    \end{itemize} 
\end{definition} 
% subsection BFS (end)

\textbf{DFS} est meilleur que \textbf{BFS} dans les cas suivant: 
\begin{itemize}
    \item Si il y a des limitations de mémoire 
\end{itemize}

\textbf{BFS} est meilleur que \textbf{DFS} dans les cas suivant: 
\begin{itemize}
    \item Si on veut trouver la solution la plus courte
\end{itemize}

\subsection{Iterative deepening} % (fold)
\label{sub:iterative_deepening}
\begin{note}
    L'idée est d'avoir les avantages mémoire de \textbf{DFS} et la solution optimale de \textbf{BFS}
\end{note}

\begin{definition}{Iterative deepening}{iterdeep}

    L'exploration itérative en profondeur (\textbf{Iterative deepening}) est une stratégie de 
    recherche qui explore l'arbre en faisant une recherche en profondeur avec une limite de profondeur de 
    1, puis 2, puis 3, etc. jusqu'à ce que la solution soit trouvée.


    % TODO: Se renseigner sur ça 
    % L'exploration itérative en profondeur (\textbf{Iterative deepening}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    % \begin{itemize}
    %     \item \textbf{Frontière}: une pile (LIFO)
    %     \item \textbf{Stratégie}: on choisit le noeud le plus profond de la frontière
    % \end{itemize} 
\end{definition}

\begin{remark}\leavevmode
    Même si cette algorithme visite plusieurs fois les mêmes noeuds, ça n'a pas vraiment d'impact
    car le nombre de noeuds est réduit (car on mise de le trouver avant d'atteindre la limite de profondeur)
\end{remark}

% subsection Iterative deepening (end)


\subsection{UCS} % (fold) 
\label{sub:ucs} 

\begin{definition}{UCS}{ucs}
    La recherche par coût uniforme (\textbf{UCS}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une file de priorité
        \item \textbf{Stratégie}: on choisit le noeud ayant le plus petit coût de la frontière
    \end{itemize} 
\end{definition} 




Pour ananlyser un algorithme, on va utilser ces différentes propriétés:
\begin{itemize}
    \item \textbf{Complet}: l'algorithme trouve toujours une solution si elle existe
    \item \textbf{Optimal}: l'algorithme trouve toujours la solution optimale (avec le plus petit coût)
    \item \textbf{Complexité en temps}: Combien de temps l'algorithme prend pour trouver une solution
    \item \textbf{Complexité en espace}: Combien de mémoire l'algorithme prend pour trouver une solution
\end{itemize}

\begin{table}[H]
    \caption{Comparaison stratégie d'exploration}\label{tab:searchcomp}
    \begin{center}
        \begin{tabular}[c]{|l||l|l|l|l|}
            \hline
            \multicolumn{1}{|c|}{\textbf{Critère}} & 
            \multicolumn{1}{|c|}{\textbf{Largeur}} &
            \multicolumn{1}{c|}{\textbf{Cout uniforme}} &
            \multicolumn{1}{c|}{\textbf{Profondeur}} &
            \multicolumn{1}{c|}{\textbf{Profondeur itérative}} \\

            \hline
            \textbf{Complet}& Oui & Oui & Non & Oui \\ 
            \hline
            \textbf{Optimal}& Oui & Oui & Non & Oui\\ 
            \hline
            \textbf{Temps}& $O(b^d)$ & $O(b^{\frac{C^*}{\epsilon}})$ & $O(b^m)$ & $O(b^d)$\\ 
            \hline
            \textbf{Espace}& $O(b^d)$ & $O(b^{\frac{C^*}{\epsilon}})$ & $O(bm)$ & $O(bd)$\\

            \hline
        \end{tabular}
    \end{center}
\end{table}

% section Recherche (end)

\newpage

\section{Recherche Informée} % (fold) 
\label{sec:recherche_informee} 

\begin{definition}{Recherche Informée}{informedsearch}

    La recherche \textbf{informée} est une stratégie de recherche qui utilise \textbf{des informations} sur l'état de l'environnement afin de le \textbf{guider} pour trouver une solution.
    Elle explore l'espace de recherche de manière \textbf{intelligente} gràce à des \textbf{heuristiques}. 
    Ces heuristiques permettent de \textbf{quantifier} la \textbf{qualité} d'un état et donc 
    de guider la recherche vers les états les plus prometteurs.
\end{definition}

\begin{remark}\leavevmode
    La performance de ces algorithmes dépendent de la qualité de l'heuristique utilisée.
\end{remark}

\begin{definition}{Heuristique}{heuristic}
    Une heuristique est une fonction qui permet d'estimer à quel point un état est \textbf{proche}
    de l'état final. Elles sont designées pour des problèmes spécifiques.
\end{definition}

\begin{examples}\leavevmode
    \begin{enumerate}
        \item \textbf{Distance Euclidéenne}: la distance entre deux points 
            en ligne droite 
        \item \textbf{Distance de Manhattan}: la distance entre deux points 
            en ligne droite mais en ne pouvant se déplacer que sur les axes 
            (pas en diagonale) 
    \end{enumerate}
\end{examples}


\subsection{Greedy Best-First Search} % (fold)
\label{sub:greedy_best_first_search}

\begin{definition}{Greedy Best-First Search}{greedybestfirstsearch}
    La recherche gloutonne (\textbf{Greedy Best-First Search}) est une stratégie de recherche qui explore l'arbre en choisissant le noeud qui semble le plus prometteur.
    \begin{itemize}
        \item \textbf{Frontière}: une file de priorité
        \item \textbf{Stratégie}: on choisit le noeud ayant la plus petite heuristique de la frontière
    \end{itemize} 
\end{definition}

\begin{figure}[H]
  \centering
  \scalebox{0.65}{
  \begin{minipage}[b]{0.30\textwidth}
    \centering
    \begin{tabular}[c]{|ll|ll|}
        \hline
        % \multicolumn{1}{c|}{\textbf{}} & 
        % \multicolumn{1}{c}{\textbf{}} \\
        % \hline
        \textbf{Arad} & 366 & \textbf{Mehadia} & 241 \\ 
        \textbf{Bucharest} & 0 & \textbf{Neamt} & 234 \\ 
        \textbf{Craiova} & 160 & \textbf{Oradea} & 380 \\ 
        \textbf{Dobreta} & 242 & \textbf{Pitesti} & 100 \\ 
        \textbf{Eforie} & 161 & \textbf{Rimnicu Vilcea} & 193 \\ 
        \textbf{Fagaras} & 176 & \textbf{Sibiu} & 253 \\ 
        \textbf{Giurgiu} & 77 & \textbf{Timisoara} & 329 \\ 
        \textbf{Hirsova} & 151 & \textbf{Urziceni} & 80 \\ 
        \textbf{Iasi} & 226 & \textbf{Vaslui} & 199 \\ 
        \textbf{Lugoj} & 244 & \textbf{Zerind} & 374 \\ 
        \hline
    \end{tabular}

    \caption{Tableau de valeure d'heuristique}
    \label{tab:heuristics}
  \end{minipage}
   }
  \hfill
  \scalebox{0.9}{
  \begin{minipage}{0.70\textwidth}
    \centering
    \includegraphics[width=\textwidth]{./pictures/greedy.png}
    \caption{Exécution de l'algo greedy}
    \label{fig:greedy}
  \end{minipage}
    }
\end{figure}


\begin{remarks}\leavevmode
    \begin{enumerate}
        \item \textbf{Complet}: Non, peut aller dans des profondeurs infinies
        \item \textbf{Optimal}: Non
        \item \textbf{Complexité en temps}: $O(b^m)$
        \item \textbf{Complexité en espace}: $O(b^m)$
        \item Il est en général meilleur que \textbf{DFS}
    \end{enumerate}
\end{remarks}

% subsection Greedy Best-First Search (end)

\subsection{A*} % (fold)
\label{sub:a_}

\begin{definition}{A*}{astar}
    L'algorithme \textbf{A*} est une stratégie de recherche qui explore l'arbre en choisissant le noeud qui semble le plus prometteur.
    \begin{itemize}
        \item \textbf{Frontière}: une file de priorité
        \item \textbf{Stratégie}: on choisit le noeud ayant le plus petit coût de la frontière
    \end{itemize} 
    La fonction d'évaluation est la suivante: 
    \begin{math}
        f(n) = g(n) + h(n)
    \end{math} 
    où $g(n)$ est le coût pour atteindre le noeud $n$ depuis la racine et 
    $h(n)$ est le cout du noeud $n$ pour aller jusqu'au but.
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.65\textwidth]{./pictures/astar.png}
    \end{center}
    \caption{Exécution de l'algo A*}\label{fig:astar}
\end{figure}

\begin{remarks}\leavevmode
    \begin{enumerate}
        \item \textbf{Complet}: Oui
        \item \textbf{Optimal}: Oui si $h(n)$ est admissible
        \item \textbf{Complexité en temps}: $O(b^d)$
        \item \textbf{Complexité en espace}: $O(b^d)$
    \end{enumerate}
\end{remarks}
% subsection A* (end)

\subsection{Creer des Heuristiques admissibles} % (fold)
\label{sub:creer_des_heuristiques_admissibles}

\begin{definition}{Admissible}{admissible}
    Une heuristique est admissible si elle ne surestime jamais le coût pour atteindre l'état final. 
    \begin{math}
        h(n) \leq h^*(n) 
    \end{math} 
    où $h^*(n)$ est le coût réel pour atteindre l'état final. 
    C'est une fonction \textbf{optimiste}
\end{definition}

\begin{definition}{Cohérent}{consitent}
    Une \textbf{heuristique} est \textbf{cohérente} si, pour chaque noeud $n$ et un successeur $n'$ de $n$ généré par une action $a$,
    le coût estimé pour atteindre l'état final depuis $n$ est inférieur ou égal au coût de l'action $a$ plus le coût estimé pour atteindre l'état final depuis $n'$. 
    \begin{math}
        h(n) \leq c(n, a, n') + h(n') 
    \end{math} 
    où $c(n, a, n')$ est le coût de l'action $a$ pour aller de $n$ à $n'$. 
\end{definition}

\begin{remark}\leavevmode
    Une heuristique cohérente est toujours admissible. 
\end{remark}

\begin{note}
    Lorsqu'on compare 2 heuristiques, on peut dire que l'heuristique $h_1$ est meilleure que $h_2$ si 
    \begin{math}
        h_1(n) \leq h_2(n) \forall n 
    \end{math}
\end{note}

Afin de créer une heuristique admissible, on peut utiliser les méthodes suivantes: 
\begin{itemize}
    \item \textbf{Relaxation}: on simplifie le problème en enlevant des contraintes
    \item \textbf{Décomposition}: on décompose le problème en sous-problèmes qui sont plus facile à résoudre
    \item \textbf{Combinaison}: on combine plusieurs heuristiques 
\end{itemize}

Il est aussi possible de stocker les valeures réelles dans une \textbf{base de donnée} 
et de les utiliser pour calculer l'heuristique (qui est dcp dans la bdd).
% subsection Creer des Heuristiques admissibles (end)

% section Recherche  Informée(end)










%================= Bibliography ========================
% \newpage
% \phantomsection % Required if hyperref is used
% \addcontentsline{toc}{section}{References} % Adding bibliography to table of contents
% \printbibliography % Print the bibliography

\end{document}
