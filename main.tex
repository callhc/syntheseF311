\documentclass[a4paper, 12pt]{extarticle}

\input{preamble.tex} 


% Based on 'Fun Template 1', available at https://www.overleaf.com/latex/templates/fun-template-1/drwvdzsrpgzz


\begin{document}

%================= Settings front page =================
\titre{Synthèse IA} %Titre du fichier .pdf
\UE{INFO-F311} %Nom de la UE
\sujet{Intelligence Artificielle} %Nom du sujet

\enseignant{T. \textsc{Lenaerts}}  %Nom des enseignants
% Use \\ TO BREAK LINE

\eleves{Rayan \textsc{Contuliano Bravo}}
% \maketitle
\makemargins %Afficher les marges
\makefrontpage
\maketoc

%=======================================================

% this is the orginal latex code of the template
% \input{example}

%================= Content =============================
\section{Introduction} % (fold)
\label{sec:introduction}

\begin{definition}{Qu'est-ce que l'ia}{iadef}
    L'intelligence artificielle est une branche de l'informatique qui crée des systèmes 
    qui pensent de manière \textbf{rationnelle}
\end{definition}

\begin{definition}{Décisions rationnelles}{decisionsrationnelles}
    Penser de manière rationnelle signifie qu'on va se concentrer sur le \textbf{choix de décisions}
    qui \textit{maximisent la probabilité} d'atteindre un objectif donné. On va faire agir les systèmes de 
    manière \textbf{optimale}
\end{definition}
\begin{remarks}\leavevmode
\begin{enumerate}
    \item     Être rationel signifie donc \textbf{maximiser} l'utilité attendue.
    \item On définis un objectif par son \textbf{utilité}.
\end{enumerate}
\end{remarks}

\begin{definition}{Agent}{agent}
    Un agent est un système qui perçoit son environnement par des \textbf{capteurs} et agit sur celui-ci par des \textbf{effecteurs}.
\end{definition}

\begin{definition}{Agent rationnel}{agentrationnel}
    Un agent rationnel est un agent qui agit de manière à maximiser son utilité attendue. 
\end{definition}

\begin{remark}\leavevmode
    Les \textbf{capteurs}, \textbf{effecteurs} et l'\textbf{environnement} permettent à l'agent 
    de percevoir et d'agir sur le monde de manière \textbf{rationnelle}. L'\textbf{agent} est le système qui prend les décisions.
\end{remark}

\begin{definition}{Fonction agent}{funca}
    La fonction agent est une fonction qui prend en entrée une séquence de perceptions et retourne une action.
    \begin{math}
        f: \PP^* \rightarrow \SA \SP
    \end{math}
\end{definition}

\begin{example}\leavevmode
    % inserer une image
    \begin{figure}[H]
        \centering
        \includegraphics[width=0.7\textwidth]{./pictures/agent_func.png}
        \caption{Représentation fonction agent dans le jeu Tetris}
        \label{fig:agent} 
    \end{figure}
\end{example}

\begin{definition}{Programe Agent}{progagent}
    Un \textbf{programe agent} $l$ est \underline{exécuté} sur une \textbf{machine} $M$ 
    afin d'\underline{implémenter} la fonction agent $f$.
\end{definition}
\begin{remark}\leavevmode
    Les machines dans le monde réel sont \textbf{imparfaites} et \textbf{limitées} en temps et en mémoire.
\end{remark}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.25\textwidth]{./pictures/vac_state.png}
    \end{center}
    \caption{Etat de l'environnement de l'aspirateur}\label{fig:vac_state}
\end{figure}

% WARNING: Pas sur que ce soit utile/bonne façon de faire
\begin{example}\leavevmode
    Nous pouvons représenter un aspirateur comme un agent qui perçoit son environnement par des capteurs et agit sur celui-ci par des effecteurs.
    \begin{itemize}
        \item \textbf{Perception}: capteurs qui détectent la saleté et sa localisation dans l'espace
        \item \textbf{Action}: effecteurs qui déplacent l'aspirateur dans l'espace et aspire ou non
    \end{itemize}
    En imaginant la situation en figure \ref{fig:vac_state}, nous pouvons définir la fonction agent de l'aspirateur comme suit:
    \begin{table}[H]
        \caption{Fonction agent de l'aspirateur}\label{tab:agent_func}
        \begin{center}
            \begin{tabular}[c]{|l|l|}
                \hline
                \multicolumn{1}{|c|}{\textbf{Sequence de perception}} & 
                \multicolumn{1}{c|}{\textbf{Action}} \\
                \hline

                [A, Clean] & Right \\
                \hline
                [A, Dirty] & Suck \\
                \hline
                [B, Clean] & Left\\
                \hline
                [B, Dirty] & Suck\\
                \hline
                [A, Clean], [B, Clean] & Left\\
                \hline
                [A, Clean], [B, Dirty] & Suck\\
                \hline
                etc... & etc...\\
                \hline
            \end{tabular}
        \end{center}
    \end{table}
\end{example}

Pour que notre agent soit bien rationnel, il nous faut une manière de \textbf{mesurer} la \textbf{performance}
de celui-ci. Pour cela, nous allons définir une \textbf{fonction de performance} qui va mesurer la qualité des actions de l'agent.

\begin{example}\leavevmode
    On peut lui faire gagner des points ou bien lui en retirer en fonction d'une action
\end{example}
De cette manière, l'agent va savoir quelles actions lui permettent de \textbf{maximiser} son utilité attendue.

Afin de bien déterminer un environnement, les particularité de notre agents, il nous faut 
\textbf{avant toute chose} définir \textbf{\textcolor{red}{PEAS}}

\begin{definition}{PEAS}{peas}
    \begin{itemize}
        \item \textbf{Performance}: mesure de la qualité des actions de l'agent
        \item \textbf{Environnement}: type d'environnement dans lequel l'agent va évoluer
        \item \textbf{Actuateurs}: les effecteurs de l'agent
        \item \textbf{Sensors}: les capteurs de l'agent
    \end{itemize} 
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.25\textwidth]{./pictures/pacman.png}
    \end{center}
    \caption{Environnement Pacman}\label{fig:pacman}
\end{figure}

\begin{example}\leavevmode
    Pour l'environnement Pacman de la figure \ref{fig:pacman}, nous pouvons définir PEAS comme suit:
    \begin{itemize}
        \item \textbf{Performance}: -1/pas, +10/nourriture, +500/partie gagnées, -500/mort, +200/tuer un fantôme effrayé
        \item \textbf{Environnement}: labyrinthe \textbf{dynamique }de pacman
        \item \textbf{Actuateurs}: Haut, Bas, Gauche, Droite
        \item \textbf{Capteurs}: L'état entier visible
    \end{itemize}



\end{example}

\begin{definition}{Types d'environnement}{envtype}
    Il y a plusieur type d'environnement:

    \begin{itemize}
        \item \textbf{Mono-agent}: un seul agent
        \item \textbf{Multi-agent}: plusieurs agents qui maximisent leur \textbf{propre} tâche (coop ou concurentiel)
        \item \textbf{Déterministe}: l'état de l'env est déterminé \textbf{seulement} par les actions de l'agent
        \item \textbf{Stochastique}: l'environnement est non déterministe
        \item \textbf{Épisodique}: les actions de l'agent n'affectent pas les actions futures
        \item \textbf{Séquentiel}: les actions de l'agent affectent les actions futures
        \item \textbf{Dynamique}: l'environnement peut changer pendant que l'agent réfléchit
        \item \textbf{Statique}: l'environnement ne change pas pendant que l'agent réfléchit
        \item \textbf{Complètement observable}: les capteurs de l'agent perçoivent l'état complet de l'environnement
        \item \textbf{Partiellement observable}: les capteurs de l'agent perçoivent une partie de l'état de l'environnement
        \item \textbf{Discret}: un nombre fini d'états
        \item \textbf{Continu}: un nombre infini d'états
        \item \textbf{Connu}: l'agent connait les lois de l'environnement
    \end{itemize}
\end{definition}

Il existe plusieurs types d'agents qui répondent à des environnements plus complexes:
\begin{itemize}
    \item \textbf{Agent réflexe simple}: l'agent choisit son action en fonction de la \textbf{dernière} perception
    \item \textbf{Agent réflexe basé sur un modèle}: l'agent choisit son action en fonction de la \textbf{dernière} perception et d'un \textbf{état interne}(dépend de l'\textbf{historique} des perceptions) 
    % \item \textbf{Agent réflexe avec état}: l'agent choisit son action en fonction de la \textbf{dernière} perception et de l'\textbf{historique} des perceptions
    \item \textbf{Agent fondés sur des buts}: l'agent choisit son action en fonction de la dernière perception 
        ainsi que des infos relatives à l'objectif
    \item \textbf{Agent fondés sur l'utilité}: l'agent choisit son action en fonction de 
        sa satisfaction par rapport à l'état résultant
\end{itemize}
% section Introduction (end)

\section{Recherche} % (fold)
\label{sec:recherche}

\begin{definition}{Agent de Plannification}{planningagent}
    Un agent de plannification font des \textbf{hypothèses} sur les conséquences des actions entreprises
    et utilise un \textbf{modèle} de l'environnement pour trouver un plan qui atteint son objectif.
\end{definition}

\begin{note}
    Un plan est une séquence d'actions qui mène à l'objectif.
\end{note}

\subsection{Problème de recherches} % (fold)
\label{sub:probleme_de_recherches}

\begin{definition}{Problème de Recherche}{searchprob}
    Un problème de recherche est défini par:
    \begin{itemize}
        \item \textbf{Ensemble d'État $S$}: Une situation dans lequel l'environnement peut être agencé
        \item \textbf{État initial $s_o$}: l'état dans lequel le problème commence
        % \item \textbf{Actions}: les actions possibles
        % \item \textbf{Transition}: la fonction qui définit les conséquences des actions
        \item \textbf{Actions $A(s)$}: les actions possibles dans l'état $s$
        \item \textbf{Modèle de Transition $Result(s, a)$}: la fonction qui définit les conséquences des actions
        \item \textbf{Solution}: Une séquence d'actions qui mène de l'état initial à l'état final
        \item \textbf{État final}: l'état que l'on veut atteindre
    \end{itemize}
\end{definition}

% Fais un graph pour illustrer la roumanie

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.70\textwidth]{./pictures/roumanie.png}
    \end{center}
    \caption{Représentation simple de la Roumanie en graphe}\label{fig:romania}
\end{figure}



\begin{example}\leavevmode
    Voyage en Roumanie:
    \begin{itemize}
        \item \textbf{États}: les villes de Roumanie
        \item \textbf{État initial}: Arad
        \item \textbf{Actions}: les routes entre les villes adjacentes
        \item \textbf{Modèle de transition}: Atteindre une ville adjacente
        \item \textbf{Cout de l'action}: distance entre les villes
        \item \textbf{État final}: Bucharest 
    \end{itemize}
\end{example}

% subsection Probleme de recherches (end)

\subsection{Graphe d'espace d'état} % (fold)
\label{sub:graphe_d_espace_d_etat}

\begin{definition}{Graphe d'espace d'état}{stategraph}
    Un graphe d'espace d'état est un graphe qui représente les états et les actions possibles.
    \begin{itemize}
        \item \textbf{Noeuds}: les états
        \item \textbf{Arêtes}: les actions
    \end{itemize} 
    L'état initial est le noeud racine et l'état final est un noeud (ou plusieurs ?).
\end{definition}

\begin{warning}
    Dans ce genre de graphe, chaque état n'est représenté qu'\textbf{une seule fois}.
\end{warning}

\begin{remark}\leavevmode
    Il est fortement possible de ne pas pouvoir représenter un problème de recherche par un graphe d'espace d'état car 
    il y a \textbf{trop d'états} ou que les états sont \textbf{continus}.
\end{remark}

% subsection Graphe d'espace d'etat (end)

\subsection{Arbres de Recherches} % (fold)
\label{sub:arbres_de_recherches}

\begin{definition}{Arbre de Recherche}{searchtree}
    Un arbre de recherche est un arbre qui représente les états et les actions possibles.
    \begin{itemize}
        \item \textbf{Noeuds}: les états, plans pour arriver à ces états
        \item \textbf{Arêtes}: les actions
        \item \textbf{Enfants}: les états suivants (\textit{succeseurs})
    \end{itemize} 
    L'état initial est le noeud racine et l'état final est un noeud (ou plusieurs ?). 
    Les noeuds peuvent être représentés plusieurs fois, (\textbf{il est donc plus grand qu'un graphe d'espace d'état.})
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.75\textwidth]{./pictures/romst.png}
    \end{center}
    \caption{Arbre de recherche de la figure \ref{fig:romania}}\label{fig:romst}
\end{figure}

\subsubsection{Recherche dans un arbre de recherche} % (fold)
\label{sec:recherche_dans_un_arbre_de_recherche}

\begin{algorithm}[H]
    \floatname{algorithm}{Recherche dans un Arbre}
    \caption{Algorithme de recherche}\label{alg:stsearch}
    \begin{algorithmic}
        \Function{Tree-Search}{problème, stratégie} 
        \State initialise un noeud avec l'état initial du problème

        \Loop{
            \If{il ne peut plus y avoir d'état à explorer}
                \State \Return Erreur
            \EndIf
            \State choisis un noeud non exploré selon la stratégie
            \If{le noeud est l'état final}
                \State \Return le plan qui mène à l'état final
            \Else
                \State Développe le noeud et ajoute ses enfants à l'arbre
            \EndIf
        }
        \EndLoop
        \EndFunction
    \end{algorithmic}
\end{algorithm}

\begin{remarks}\leavevmode
\begin{enumerate}
    \item La frontière est l'ensemble des noeuds non explorés de l'arbre
    \item Pour développer un noeud de la frontiere, on le retire de la frontière et on l'ajoute à l'ensemble des noeuds explorés
        ses enfants sont ajoutés à la frontière
\end{enumerate}
\end{remarks}

% subsubsection Recherche dans un arbre de recherche (end)

% subsection Arbres de Recherches (end)


\subsection{DFS} % (fold)
\label{sub:dfs}

\begin{definition}{DFS}{dfs}
    La recherche en profondeur (\textbf{DFS}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une pile (LIFO)
        \item \textbf{Stratégie}: on choisit le noeud le plus profond de la frontière
    \end{itemize} 
\end{definition}
% subsection DFS (end)

\subsection{BFS} % (fold) 
\label{sub:bfs} 

\begin{definition}{BFS}{bfs}
    La recherche en largeur (\textbf{BFS}) est une stratégie de recherche qui explore l'arbre en allant le plus large possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une file (FIFO)
        \item \textbf{Stratégie}: on choisit le noeud le moins profond de la frontière
    \end{itemize} 
\end{definition} 
% subsection BFS (end)

\textbf{DFS} est meilleur que \textbf{BFS} dans les cas suivant: 
\begin{itemize}
    \item Si il y a des limitations de mémoire 
\end{itemize}

\textbf{BFS} est meilleur que \textbf{DFS} dans les cas suivant: 
\begin{itemize}
    \item Si on veut trouver la solution la plus courte
\end{itemize}

\subsection{Iterative deepening} % (fold)
\label{sub:iterative_deepening}
\begin{note}
    L'idée est d'avoir les avantages mémoire de \textbf{DFS} et la solution optimale de \textbf{BFS}
\end{note}

\begin{definition}{Iterative deepening}{iterdeep}

    L'exploration itérative en profondeur (\textbf{Iterative deepening}) est une stratégie de 
    recherche qui explore l'arbre en faisant une recherche en profondeur avec une limite de profondeur de 
    1, puis 2, puis 3, etc. jusqu'à ce que la solution soit trouvée.


    % TODO: Se renseigner sur ça 
    % L'exploration itérative en profondeur (\textbf{Iterative deepening}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    % \begin{itemize}
    %     \item \textbf{Frontière}: une pile (LIFO)
    %     \item \textbf{Stratégie}: on choisit le noeud le plus profond de la frontière
    % \end{itemize} 
\end{definition}

% subsection Iterative deepening (end)


\subsection{UCS} % (fold) 
\label{sub:ucs} 

\begin{definition}{UCS}{ucs}
    La recherche par coût uniforme (\textbf{UCS}) est une stratégie de recherche qui explore l'arbre en allant le plus loin possible dans une branche avant de revenir en arrière. 
    \begin{itemize}
        \item \textbf{Frontière}: une file de priorité
        \item \textbf{Stratégie}: on choisit le noeud ayant le plus petit coût de la frontière
    \end{itemize} 
\end{definition} 




Pour ananlyser un algorithme, on va utilser ces différentes propriétés:
\begin{itemize}
    \item \textbf{Complet}: l'algorithme trouve toujours une solution si elle existe
    \item \textbf{Optimal}: l'algorithme trouve toujours la solution optimale (avec le plus petit coût)
    \item \textbf{Complexité en temps}: Combien de temps l'algorithme prend pour trouver une solution
    \item \textbf{Complexité en espace}: Combien de mémoire l'algorithme prend pour trouver une solution
\end{itemize}

\begin{table}[H]
    \caption{Comparaison stratégie d'exploration}\label{tab:searchcomp}
    \begin{center}
        \begin{tabular}[c]{|l||l|l|l|l|}
            \hline
            \multicolumn{1}{|c|}{\textbf{Critère}} & 
            \multicolumn{1}{|c|}{\textbf{Largeur}} &
            \multicolumn{1}{c|}{\textbf{Cout uniforme}} &
            \multicolumn{1}{c|}{\textbf{Profondeur}} &
            \multicolumn{1}{c|}{\textbf{Profondeur itérative}} \\

            \hline
            \textbf{Complet}& Oui & Oui & Non & Oui \\ 
            \hline
            \textbf{Optimal}& Oui & Oui & Non & Oui\\ 
            \hline
            \textbf{Temps}& $O(b^d)$ & $O(b^{\frac{C^*}{\epsilon}})$ & $O(b^m)$ & $O(b^d)$\\ 
            \hline
            \textbf{Espace}& $O(b^d)$ & $O(b^{\frac{C^*}{\epsilon}})$ & $O(bm)$ & $O(bd)\\

            \hline
        \end{tabular}
    \end{center}
\end{table}

% section Recherche (end)










%================= Bibliography ========================
% \newpage
% \phantomsection % Required if hyperref is used
% \addcontentsline{toc}{section}{References} % Adding bibliography to table of contents
% \printbibliography % Print the bibliography

\end{document}
