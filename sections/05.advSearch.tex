Dans les chapitres précédents, nous avons vu comment résoudre des problèmes de recherche. 
Dans ce chapitre, nous allons nous concentrer sur les problèmes où nous devons \textbf{battre nos adversaire} 
dans des jeux à \textbf{deux ou plusieurs joueurs}.

\subsection{Définition d'un jeu} % (fold)
\label{sub:definition_d_un_jeu}

\begin{definition}{Jeu}{game}
    Un jeu est un problème de recherche avec les caractéristiques suivantes:
    \begin{itemize}
        \item \textbf{État initial, $s_0$}: la position initiale du jeu.
        \item \textbf{Joueur, $Player(s)$}: le joueur qui doit jouer.
        \item \textbf{Actions, $Action(s)$}: les coups possibles pour un joueur.
        \item \textbf{Modèle de transition, $Result(a, s)$}: L'état $s'$ qui résulte de l'action $a$ dans l'état $s$
        \item \textbf{Fonction de terminal, $isTerminal(s)$}: la fonction qui détermine si le jeu est terminé
        \item \textbf{Utilité, $Utility(s, p)$}: la fonction qui détermine le score du jeu sur les états terminaux. Qui gagne,et combien.
            $p$ est le joueur.
    \end{itemize} 
\end{definition}
\begin{note}
    Il y a plusieurs types de jeux:
    \begin{itemize}
        \item \textbf{Jeux à somme nulle}: la somme des utilités des joueurs est toujours égale à 0. Si l'un \textbf{gagne}, l'autre \textbf{perd}.
        \item \textbf{Jeux à somme général}: Les agents peuvent avoir des utilités différentes. Si l'un \textbf{gagne}, l'autre \textbf{ne perd pas forcément}. (\textit{Coop}, \textit{...})
        \item \textbf{Jeux d'équipes}: Les agents jouent en équipe contre d'autres agents.
    \end{itemize}
\end{note}
% subsection Definition d'un jeu (end)
Les algorithmes de recherche que nous avons vu précédemment ne sont pas adaptés pour les jeux car ils ne prennent pas en compte le fait que l'adversaire joue aussi. 
Nous allons donc voir des algorithmes qui vont prendre en compte le fait que l'adversaire joue aussi et vont alors recommander le meilleur coup à jouer selon toutes les possibilités.

\subsection{Minimax} % (fold)
\label{sub:minimax}

\begin{definition}{Minimax}{minimax}
    L'algorithme \textbf{Minimax} est un algorithme qui permet de trouver le meilleur coup à jouer dans un jeu \textbf{déterministe} à \textbf{somme nulle}.
    Le principe est simple, nous imaginons 2 joueurs qui jouent l'un contre l'autre, \textbf{Min} et \textbf{Max}.
    Le but de \textbf{Max} est de maximiser l'utilité et le but de \textbf{Min} est de minimiser l'utilité sachant 
    que l'autre joueur va jouer de manière optimale.
\end{definition}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.55\textwidth]{./pictures/minimax.png}
    \end{center}
    \caption{Minimax dans un arbre.}\label{fig:minimaxtree}
\end{figure}


L'algorithme va généré l'arbre de recherche jusqu'aux étas \textbf{terminaux} pour utiliser la fonction d'utilité. 
Il traite ensuite ces valeurs en remontant l'arbre et les choisit en fonction du joueur qui doit jouer (\textbf{Min} ou \textbf{Max})
\begin{note}
    Pour ne pas généré tous l'arbre, on peut utiliser une \textbf{profondeur limitée}.
\end{note}

Si il y a plus de 2 joueurs, nous pouvons assigner à chaque noeud un tuple de valeurs qui représente l'utilité pour chaque joueur. 
Chaque joueur va alors choisir le coup qui maximise son utilité. 

\begin{remark}\leavevmode
    Cet algortihme est basé sur \textbf{DFS}. 
    \begin{itemize}
        \item \textbf{Complexité en temps}: $O(b^m)$
        \item \textbf{Complexité en espace}: $O(bm)$
    \end{itemize}
\end{remark}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.65\textwidth]{./pictures/multiminimax.png}
    \end{center}
    \caption{Représentation en Multijoueur}\label{fig:mutliminimax}
\end{figure}

Cette algorithme n'est pas adapté pour les jeux où il y a beaucoup de noeuds car il va générer tout l'arbre de recherche. 
Nous allons donc voir des algorithmes qui vont couper les branches qui ne sont pas intéressantes.
\begin{algorithm}[H]
    \floatname{algorithm}{Minimax}
    \caption{Algorithme Minimax}\label{alg:minimax}
    \begin{algorithmic}
        \Function{Minimax-Search}{game, state} 
        \State player $\leftarrow$ game.\Call{To-Move}{state}
        
        \If{player = max}
            \State value, action $\leftarrow$ \Call{Max-Value}{game, state} 
        \Else 
            \State value, action $\leftarrow$ \Call{Min-Value}{game, state}
        \EndIf
        \State \Return action
        \EndFunction
        \vspace{0.5cm}
        \Function{Max-Value}{game, state}
        \If{game.\Call{Terminal-Test}{ state}}
            \State \Return game.\Call{Utility}{state, player}, $null$
        \EndIf 
        \State value, action $\leftarrow -\infty, null$

        \For{action in game.\Call{Actions}{state}}
            \State value2, action2 $\leftarrow$ \Call{Min-Value}{game, game.\Call{Result}{state, action}}
            \If{value2 $>$ value}
                \State value, action $\leftarrow$ value2, action2
            \EndIf
        \EndFor

        \Return value, action
        \EndFunction
        \vspace{0.5cm}
        \Function{Min-Value}{game, state} 
        \If{game.\Call{Terminal-Test}{ state}}
            \State \Return game.\Call{Utility}{state, player}, $null$
        \EndIf 
        \State value, action $\leftarrow \infty, null$ 

        \For{action in game.\Call{Actions}{state}}
        \State value2, action2 $\leftarrow$ \Call{Max-Value}{game, game.\Call{Result}{state, action}}%{game, game.\Call{Result}{state, action}}
            \If{value2 $<$ value}
                \State value, action $\leftarrow$ value2, action2 
            \EndIf
        % }
        \EndFor
        \State \Return value, action
        \EndFunction
    \end{algorithmic} 
\end{algorithm}
% subsection Minimax (end)
\newpage

\subsection{Alpha-Beta pruning} % (fold)
\label{sub:alpha_beta_pruning}

\begin{definition}{Alpha-Beta pruning}{alphabeta}
    L'algorithme \textbf{Alpha-Beta pruning} est un algorithme qui permet de trouver le meilleur coup à jouer dans un jeu \textbf{déterministe} à \textbf{somme nulle}.
    Il est basé sur l'algorithme \textbf{Minimax} mais il va \textbf{couper} les branches qui ne sont pas intéressantes.
    Il utilise 2 paramètres, $\alpha$ et $\beta$ qui représentent les valeurs minimales et maximales que l'on à trouvé jusqu'à présent.
    \begin{itemize}
        \item $\alpha$ est la meilleure option (valeure la plus haute) que le joueur \textbf{Max} est assuré d'obtenir. 
            \textbf{Au MOINS}.
        \item $\beta$ est la meilleure option (valeure la plus basse) que le joueur \textbf{Min} est assuré d'obtenir. 
            \textbf{Au PLUS}.
    \end{itemize} 
\end{definition}

Si le noeud est un noeud \textbf{Max}, on va mettre à jour $\alpha$ avec la valeur maximale trouvée jusqu'à présent. 
Si le noeud est un noeud \textbf{Min}, on va mettre à jour $\beta$ avec la valeur minimale trouvée jusqu'à présent. 
Tous les noeuds qui sont entre $\alpha$ et $\beta$ ne seront pas visités car ils ne sont pas intéressants.

\begin{remark}\leavevmode
    Le meilleur situation pour cette algorithme est quand les meilleurs coups sont toujours le 
    premier coup à être évalué (\textit{plus à gauche})
\end{remark}

\begin{figure}[H]
    \begin{center}
        \includegraphics[width=0.65\textwidth]{./pictures/alphabeta.png}
    \end{center}
    \caption{Alpha-Beta pruning dans un arbre}\label{fig:alphabeta} 
\end{figure}

\begin{remark}\leavevmode
    La complexité en temps est généralement plus petite que celle de minimax
    \begin{itemize}
        \item \textbf{Complexité en temps}: $O(b^{m/2})$ avec les noeuds dans le \textbf{bon} ordre
            et $O(b^{3m/4})$ si les noeuds sont visités aléatoirement.
        \item \textbf{Complexité en espace}: $O(bm)$ et $O(\sqrt{b})$ si les noeuds sont dans le bon ordre.
    \end{itemize}
\end{remark}

\begin{note}
    Même si l'on ne visite pas tous les noeuds, on a quand même trouver la solution optimale.
\end{note}

Si cet algorithme n'est pas suffisant, on peut utilisé une fonction d'évaluation qui permet d'évaluer les noeuds 
qui ne sont pas des états terminaux pour estimer leur utilité.

\scalebox{0.8}{
    \begin{minipage}{\textwidth}
        \centering
        \begin{algorithm}[H]
            \floatname{algorithm}{$\alpha-\beta$ pruning}
            \caption{Algorithme $\alpha-\beta$ pruning}\label{alg:alphabeta}
            \begin{algorithmic}
                \Function{Alpha-Beta-Search}{game, state} 
                \State player $\leftarrow$ game.\Call{To-Move}{state}
                \State value, action $\leftarrow$ \Call{Max-Value}{game, state, $-\infty$, $+\infty$}
                \State \Return action
                \EndFunction
                \vspace{0.5cm}

                \Function{Max-Value}{game, state, $\alpha$, $\beta$}
                \If{game.\Call{Terminal-Test}{ state}}
                    \State \Return game.\Call{Utility}{state, player}, $null$
                \EndIf 
                \State value, action $\leftarrow -\infty, null$

                \For{action in game.\Call{Actions}{state}}
                    \State value2, action2 $\leftarrow$ \Call{Min-Value}{game, game.\Call{Result}{state, action}, $\alpha$, $\beta$}
                    \If{value2 $>$ value}
                        \State value, action $\leftarrow$ value2, action2
                        \State $\alpha \leftarrow$ \Call{Max}{$\alpha$, value}
                    \EndIf
                    \If{value $\geq \beta$}
                        \State \Return value, action 
                    \EndIf
                \EndFor
                \Return value, action
                \EndFunction

                \vspace{0.5cm}
                \Function{Min-Value}{game, state, $\alpha$, $\beta$}
                \If{game.\Call{Terminal-Test}{ state}}
                    \State \Return game.\Call{Utility}{state, player}, $null$
                \EndIf 
                \State value, action $\leftarrow \infty, null$ 

                \For{action in game.\Call{Actions}{state}}
                \State value2, action2 $\leftarrow$ \Call{Max-Value}{game, game.\Call{Result}{state, action}, $\alpha$, $\beta$}
                    \If{value2 $<$ value}
                        \State value, action $\leftarrow$ value2, action2 
                        \State $\beta \leftarrow$ \Call{Min}{$\beta$, value}
                    \EndIf
                    \If{value $ \leq \alpha$}
                        \State \Return value, action 
                    \EndIf
                \EndFor
                \State \Return value, action
                \EndFunction
            \end{algorithmic} 
        \end{algorithm}
    \end{minipage}
}

% subsection Alpha-Beta pruning (end)

\subsection{Expectimax} % (fold)
\label{sub:expectimax}

\begin{definition}{Expectimax}{expect}
    L'algorithme Expectimax est une technique d'exploration d'arbre de décision utilisée pour la prise 
    de décision dans des environnements incertains ou probabilistes. Il est souvent appliqué dans 
    des jeux et des situations où les actions des adversaires ou des événements aléatoires peuvent influencer le déroulement du jeu.
\end{definition}

C'est donc une variante de l'algorithme \textbf{Minimax} qui va prendre en compte les noeuds de \textbf{chance}. 
Ces noeuds de chance sont des noeuds où le résultat dépend du hasard ou de l'incertitude.
La valeure d'un noeud de chance est la moyenne pondérée des valeurs de ses fils.

\begin{remark}\leavevmode
    Les noeuds de chance sont comme les noeuds du joueur \textbf{MIN} mais cette fois-ci, 
    le résultat n'est pas \textbf{\textit{certain}} (Poker, lancé de dés, mauvais move, ...).
\end{remark}

\begin{note}
    Alors que minimax représente le \textbf{pire} des cas pour un joueur (l'adversaire joue de manière optimale), 
    expectimax représente le \textbf{cas moyen} pour un joueur (l'adversaire peut aussi bien jouer de manière optimale que de manière "aléatoire").
    Expectimax permet donc de prendre des opportunités que minimax ne prendrait pas car il est trop pessimiste, restrictif.
\end{note}

\begin{algorithm}[H]
    \floatname{algorithm}{Expectimax}
    \caption{Algorithme Expectimax}\label{alg:expectimax}
    \begin{algorithmic}
        \Function{Expectimax-Search}{game, state} 
        \State player $\leftarrow$ game.\Call{To-Move}{state}
        
        \If{player = max}
            \State value, action $\leftarrow$ \Call{Max-Value}{game, state} 
        \Else 
            \State value, action $\leftarrow$ \Call{Exp-Value}{game, state}
        \EndIf
        \State \Return action
        \EndFunction
        \vspace{0.5cm}
        \Function{Max-Value}{game, state}
        \If{game.\Call{Terminal-Test}{ state}}
            \State \Return game.\Call{Utility}{state, player}, $null$
        \EndIf 
        \State value, action $\leftarrow -\infty, null$

        \For{action in game.\Call{Actions}{state}}
            \State value2, action2 $\leftarrow$ \Call{Exp-Value}{game, game.\Call{Result}{state, action}}
            \If{value2 $>$ value}
                \State value, action $\leftarrow$ value2, action2
            \EndIf
        \EndFor

        \Return value, action
        \EndFunction
        \vspace{0.5cm}
        \Function{Exp-Value}{game, state} 
        \If{game.\Call{Terminal-Test}{ state}}
            \State \Return game.\Call{Utility}{state, player}, $null$
        \EndIf 
        \State value, action $\leftarrow \infty, null$ 

        \For{action in game.\Call{Actions}{state}}
        \State p $\leftarrow$ game.\Call{Probability}{state, action}
        \State value2, action2 $\leftarrow$ \Call{Max-Value}{game, game.\Call{Result}{state, action}}%{game, game.\Call{Result}{state, action}}
        \State value $\leftarrow$ value + p * value2
        \EndFor
        \State \Return value, action
        \EndFunction
    \end{algorithmic} 
\end{algorithm}

\begin{figure}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{../pictures/expectimaxdrawing.png}
    \end{center}
    \caption{Arbre Expectimax}\label{fig:expectimaxtree}
\end{figure}


\begin{note}
    Il n'est cependant pas possible d'élaguer l'arbre de recherche car pour évaluer 
    un noeud de chance, il faut évaluer tous ses fils.
\end{note}


% subsection Expectimax (end)

\subsection{Monte Carlo Tree Search (MCTS)} % (fold)
\label{sub:monte_carlo}

\begin{definition}{MCTS}{mcts}
    L'algorithme \textbf{Monte Carlo Tree Search} est un algorithme de recherche d'arbre qui utilise des simulations 
    "aléatoires" ou selon une certaine politique pour trouver la meilleure action à jouer. 
    En effet, plus on fait de simulations, plus on se rapproche de la vraie valeur de l'état. 
    Sachant cela, on va donc faire des simulations sur les noeuds qui sont les plus intéressants 
    en fonction du nombre de simulation à partir de ce noeud et de la valeur de ce noeud (\textbf{utilité}, \textbf{wins}).
    Il y a 4 étapes dans cet algorithme: 
    \begin{enumerate}
        \item \textbf{Sélection}:  L'algorithme commence par choisir un chemin dans l'arbre existant 
            en utilisant une stratégie qui combine l'exploration des nœuds prometteurs 
            et l'exploitation des nœuds déjà visités.        
        \item \textbf{Expansion}: Une fois qu'un nœud feuille est atteint, 
            l'algorithme ajoute de nouveaux nœuds pour représenter les actions possibles à partir de cet état.
        \item \textbf{Simulation}: Des simulations aléatoires sont effectuées à partir des nœuds nouvellement créés (tous ?)
            (ou des nœuds déjà existants) pour estimer la valeur de chaque action. 
            On simule  jusqu'à atteindre un état final ou une condition d'arrêt.
      \item \textbf{Backpropagation}: Les résultats des simulations sont propagés vers le haut de  
        l'arbre, mettant à jour les statistiques des nœuds visités pour refléter les nouvelles informations obtenues.
    \end{enumerate}

\end{definition}

Pour choisir le nœud à explorer, on utilise l'équation suivante: 
\begin{equation} 
    UCB(i) = \frac{w_i}{n_i} + c \sqrt{\frac{\ln N}{n_i}} 
\end{equation}
Où $w_i$ est le nombre de victoires lors des simulations à partir du noeud $i$, $n_i$ est le nombre de simulations à partir du noeud $i$,
$N$ est le nombre de simulations total du parent de $i$ et $c$ est un paramètre d'exploration qui contrôle l'importance de l'exploration par rapport à l'exploitation. 
Plus $c$ est grand, plus l'exploration est importante. 


A la fin, on choisit le noeud qui a eu le plus de simulations. En effet, 
s'il a eu beaucoup de simulations, cela veut dire qu'il est intéressant de le choisir.

\begin{note}
    Plus le nombre de simulation se rapproche de $\infty$, plus il se rapprochera du choix optimal.
\end{note}


% subsection Monte Carlo (end)


